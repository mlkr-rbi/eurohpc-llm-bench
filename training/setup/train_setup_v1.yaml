model_id: "google/gemma-2-2b"
model_label: "gemma-2-2b"
dataset_label: "macocu_v1"
output_dir_tag: "model_gemma-2-2b"
logging_dir_tag: "logs_gemma-2-2b"
quantize: True
peft: True
num_train_epochs: 0.05
gradient_accumulation_steps: 8
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
logging_steps: 10
eval_strategy: "no"
eval_steps: -1
save_steps: 500
save_total_limit: 2
learning_rate: 0.0002
weight_decay: 0.001
max_grad_norm: 0.3
warmup_ratio: 0.03
fp16: False
bf16: True
remove_unused_columns: False
ddp_find_unused_parameters: False
gradient_checkpointing: True