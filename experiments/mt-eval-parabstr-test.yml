action: evaluation # Start evaluation action
model: "HuggingFaceTB/SmolLM-135M"
tokenizer: "HuggingFaceTB/SmolLM-135M"
# quantization: "fp4"
device_map: "auto"
# max_memory: {0: "15GB", 1: "15GB"}
batch_size: 1
max_length: 1000
num_return_sequences: 1 
do_sample: False  # Optional: Enable sampling for diverse outputs
#temperature: 0.0 # strictly greedy output, no sampling, aiming for the best answer
#top_k: 50  # Optional: Top-k sampling for diversity
#top_p: 0.95  # Optional: Nucleus sampling
split: "test"
prompts: "mt-en-hr-parabstract-v1" # Set prompt configuration file
start_lang: "en" # Set starting language code
dest_lang: "hr" # Set destination language code
instruct_lang: "en" # Set instruction language code
randomize_prompts: True # Set True to randomize prompt variations
max_examples: 3 # Set maximal number of examples per dataset to limit computation time during debugging
datasets: # A list of dataset names
  - "parabstr"
metrics: # A list of metrics
  - "bleu"
#  - "gleu"
#  - "chrf"
#  - "nist"
#  - "ribes"