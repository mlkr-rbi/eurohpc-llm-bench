action: evaluation # Start evaluation action
model: "damir/yugogpt_parabstr_ft_1ep"
tokenizer: "gordicaleksa/YugoGPT"
# quantization: "fp4"
device_map: "auto"
# max_memory: {0: "15GB", 1: "15GB"}
batch_size: 1
max_length: 2000
num_return_sequences: 1 
do_sample: False  # Optional: Enable sampling for diverse outputs
temperature: 0.0 # strictly greedy output, no sampling, aiming for the best answer
#top_k: 50  # Optional: Top-k sampling for diversity
#top_p: 0.95  # Optional: Nucleus sampling
split: "test"
prompts: "mt-en-hr-parabstract-v1" # Set prompt configuration file
start_lang: "en" # Set starting language code
instruct_lang: "en" # Set instruction language code
randomize_prompts: True # Set True to randomize prompt variations
max_examples: 100 # Set maximal number of examples per dataset to limit computation time during debugging
datasets: # A list of dataset names
  - "parabstr"
metrics: # A list of metrics
  - "bleu"
#  - "gleu"
#  - "chrf"
#  - "nist"
#  - "ribes"